# Sequences, Time Series and Prediction

[<img src="cover.png" />](https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction)

En este curso, aprenderás:

- Resuelva problemas de series temporales y de previsión en TensorFlow

- Prepare los datos para el aprendizaje de series temporales utilizando las mejores prácticas

- Explore cómo pueden utilizarse las RNN y las ConvNets para las predicciones

- Construya un modelo de predicción de manchas solares utilizando datos del mundo real

Si usted es un desarrollador de software que quiere construir algoritmos escalables impulsados por IA, necesita entender 
cómo utilizar las herramientas para construirlos. Esta Specializations le enseñará las mejores prácticas para utilizar 
TensorFlow, un popular marco de trabajo de código abierto para el aprendizaje automático. 

En este cuarto curso, aprenderá a construir modelos de series temporales en TensorFlow. Primero implementará las mejores 
prácticas para preparar los datos de series temporales. También explorará cómo se pueden utilizar las RNN y las ConvNets 1D 
para la predicción. Por último, ¡aplicará todo lo aprendido a lo largo de la Especialización para construir un modelo de 
predicción de manchas solares utilizando datos del mundo real! 

El curso de Aprendizaje Automático y la Especialización en Aprendizaje Profundo de Andrew Ng enseñan los principios más 
importantes y fundacionales del Aprendizaje Automático y el Aprendizaje Profundo. Esta nueva Especialización en TensorFlow 
de deeplearning.ai le enseña cómo utilizar TensorFlow para implementar esos principios de forma que pueda empezar a construir 
y aplicar modelos escalables a problemas del mundo real. 

Para desarrollar una comprensión más profunda de cómo funcionan las redes neuronales, le recomendamos que realice la 
Especialización en Aprendizaje Profundo.

# INDEX 0

- [Sequences and Prediction](#sequences-and-prediction)
- [Weekly Assignment Create and Predict Synthetic Data](#weekly-assignment-create-and-predict-synthetic-data)
- [Deep Neural Networks for Time Series](#deep-neural-networks-for-time-series)
- [Weekly Assignment Prediction with a DNN](#weekly-assignment-prediction-with-a-dnn)
- [Recurrent Neural Networks for Time Series](#recurrent-neural-networks-for-time-series)
- [Weekly Assignment Using Layers for Sequence Processing](#weekly-assignment-using-layers-for-sequence-processing)
- [Real-world Time Series Data](#real-world-time-series-data)
- [Weekly Assignment Adding Convolutions](#weekly-assignment-adding-convolutions)

# Sequences and Prediction
[<- Return to INDEX 0](#index-0)

## INDEX 1

- [A conversation with Andrew NG W1](#a-conversation-with-andrew-ng-w1)
- [Time Series Examples](#time-series-examples)
- [Machine Learning Applied to Time Series](#machine-learning-applied-to-time-series)
- [Common Patterns in Time Series](#common-patterns-in-time-series)
- [Introduction to Time Series](#introduction-to-time-series)
- [Where to Find the Notebooks for This Course](#where-to-find-the-notebooks-for-this-course)
- [Introduction to Time Series Notebook (Lab 1)](#introduction-to-time-series-notebook-lab-1)
- [Have questions, issues or ideas? Join our Forum!](#have-questions-issues-or-ideas-join-our-forum)
- [Train, Validation and Test Sets](#train-validation-and-test-sets)
- [Metrics for Evaluating Performance](#metrics-for-evaluating-performance)
- [Moving Average and Differencing](#moving-average-and-differencing)
- [Trailing Versus Centered Windows](#trailing-versus-centered-windows)
- [Forecasting](#forecasting)
- [Forecasting Notebooks (Lab 2)](#forecasting-notebooks-lab-2)
- [Week 1 Quiz](#week-1-quiz)
- [Week 1 Wrap Up](#week-1-wrap-up)
- [Lecture Notes Week 1](#lecture-notes-week-1)

La semana 1 de nuestro curso introduce los conceptos fundamentales de las series temporales, cubriendo desde la creación y predicción de datos sintéticos hasta las redes neuronales profundas específicamente diseñadas para el tratamiento de este tipo de datos. A través de asignaciones semanales y explicaciones teóricas, exploraremos cómo las redes neuronales recurrentes pueden ser utilizadas efectivamente para procesar secuencias de tiempo. Además, abordaremos retos del mundo real mediante el uso de datos de series temporales, preparándote para aplicar lo aprendido en escenarios prácticos.

## A conversation with Andrew NG W1
[<- Return to INDEX 1](#index-1)

## Time Series Examples
[<- Return to INDEX 1](#index-1)

## Machine Learning Applied to Time Series
[<- Return to INDEX 1](#index-1)

## Common Patterns in Time Series
[<- Return to INDEX 1](#index-1)

## Introduction to Time Series
[<- Return to INDEX 1](#index-1)

## Where to Find the Notebooks for This Course
[<- Return to INDEX 1](#index-1)

## Introduction to Time Series Notebook (Lab 1)
[<- Return to INDEX 1](#index-1)

## Have questions, issues or ideas? Join our Forum!
[<- Return to INDEX 1](#index-1)

## Train, Validation and Test Sets
[<- Return to INDEX 1](#index-1)

## Metrics for Evaluating Performance
[<- Return to INDEX 1](#index-1)

## Moving Average and Differencing
[<- Return to INDEX 1](#index-1)

## Trailing Versus Centered Windows
[<- Return to INDEX 1](#index-1)

## Forecasting
[<- Return to INDEX 1](#index-1)

## Forecasting Notebooks (Lab 2)
[<- Return to INDEX 1](#index-1)

## Week 1 Quiz
[<- Return to INDEX 1](#index-1)

## Week 1 Wrap Up
[<- Return to INDEX 1](#index-1)

## Lecture Notes Week 1
[<- Return to INDEX 1](#index-1)

# Weekly Assignment Create and Predict Synthetic Data
[<- Return to INDEX 0](#index-0)

## Assignment Troubleshooting Tips

## Downloading your Notebooks and Refreshing your Workspace

## Working with Generated Time Series

# Deep Neural Networks for Time Series
[<- Return to INDEX 0](#index-0)

## INDEX 2

- [A Conversation with Andrew Ng W2](#a-conversation-with-andrew-ng-w2)
- [Preparing Features and Labels Notebook (Lab 1)](#preparing-features-and-labels-notebook-lab-1)
- [Preparing Features and Labels](#preparing-features-and-labels)
- [Preparing Features and Labels (screencast)](#preparing-features-and-labels-screencast)
- [Single Layer Network Notebook (Lab 2)](#single-layer-network-notebook-lab-2)
- [Feeding Windowed Dataset into Neural Network](#feeding-windowed-dataset-into-neural-network)
- [Single Layer Neural Network](#single-layer-neural-network)
- [Machine Learning on Time Windows](#machine-learning-on-time-windows)
- [Prediction](#prediction)
- [More on Single Layer Neural Network](#more-on-single-layer-neural-network)
- [Deep Neural Network Notebook (Lab 3)](#deep-neural-network-notebook-lab-3)
- [Deep Neural Network Training, Tuning and Prediction](#deep-neural-network-training-tuning-and-prediction)
- [Deep Neural Network](#deep-neural-network)
- [Week 2 Quiz](#week-2-quiz)
- [Week 2 Wrap Up](#week-2-wrap-up)
- [Lecture Notes Week 2](#lecture-notes-week-2)

Durante la semana 2, intensificamos nuestro enfoque en cómo preparar adecuadamente características y etiquetas, facilitando el camino hacia la construcción de una red neuronal de una sola capa. Exploraremos en detalle cómo alimentar conjuntos de datos segmentados a nuestras redes, optimizar el tamaño del lote, y ajustar la tasa de aprendizaje dinámicamente. La introducción de las Redes Neuronales Profundas (DNN) y su entrenamiento, sintonización y predicción ocupará un lugar central, proporcionándote una comprensión robusta de estos conceptos clave para el análisis de series temporales.

## A Conversation with Andrew Ng W2
[<- Return to INDEX 2](#index-2)

## Preparing Features and Labels Notebook (Lab 1)
[<- Return to INDEX 2](#index-2)

## Preparing Features and Labels
[<- Return to INDEX 2](#index-2)

## Preparing Features and Labels (screencast)
[<- Return to INDEX 2](#index-2)

## Single Layer Network Notebook (Lab 2)
[<- Return to INDEX 2](#index-2)

## Feeding Windowed Dataset into Neural Network
[<- Return to INDEX 2](#index-2)

## Single Layer Neural Network
[<- Return to INDEX 2](#index-2)

## Machine Learning on Time Windows
[<- Return to INDEX 2](#index-2)

## Prediction
[<- Return to INDEX 2](#index-2)

## More on Single Layer Neural Network
[<- Return to INDEX 2](#index-2)

## Deep Neural Network Notebook (Lab 3)
[<- Return to INDEX 2](#index-2)

## Deep Neural Network Training, Tuning and Prediction
[<- Return to INDEX 2](#index-2)

## Deep Neural Network
[<- Return to INDEX 2](#index-2)

## Week 2 Quiz
[<- Return to INDEX 2](#index-2)

## Week 2 Wrap Up
[<- Return to INDEX 2](#index-2)

## Lecture Notes Week 2
[<- Return to INDEX 2](#index-2)

# Weekly Assignment Prediction with a DNN
[<- Return to INDEX 0](#index-0)

## Forecasting Using Neural Networks

# Recurrent Neural Networks for Time Series
[<- Return to INDEX 0](#index-0)

## INDEX 3

- [A Conversation with Andrew Ng W3](#a-conversation-with-andrew-ng-w3)
- [Conceptual Overview](#conceptual-overview)
- [RNN Notebook (Lab 1)](#rnn-notebook-lab-1)
- [Shape of the Inputs to the RNN](#shape-of-the-inputs-to-the-rnn)
- [Outputting a Sequence](#outputting-a-sequence)
- [Lambda Layers](#lambda-layers)
- [Adjusting the Learning Rate Dynamically](#adjusting-the-learning-rate-dynamically)
- [More Info on Huber Loss](#more-info-on-huber-loss)
- [LSTM](#lstm)
- [Link to the LSTM Lesson](#link-to-the-lstm-lesson)
- [LSTM Notebook (Lab 2)](#lstm-notebook-lab-2)
- [Coding LSTMs](#coding-lstms)
- [Week 3 Quiz](#week-3-quiz)
- [Week 3 Wrap Up](#week-3-wrap-up)
- [Lecture Notes Week 3](#lecture-notes-week-3)

La tercera semana está dedicada a las Redes Neuronales Recurrentes (RNN), con un fuerte énfasis en entender las Formas de los Inputs hacia las RNN, la implementación de Capas Lambda, y el uso de LSTM (Long Short-Term Memory) para mejorar la precisión de nuestras predicciones. Examinaremos cómo las LSTMs pueden ser aplicadas a datos del mundo real, como los obtenidos de la observación de manchas solares, llevando a cabo ejercicios prácticos dirigidos a entrenar y afinar modelos para realizar predicciones precisas.

## A Conversation with Andrew Ng W3
[<- Return to INDEX 3](#index-3)

## Conceptual Overview
[<- Return to INDEX 3](#index-3)

## RNN Notebook (Lab 1)
[<- Return to INDEX 3](#index-3)

## Shape of the Inputs to the RNN
[<- Return to INDEX 3](#index-3)

## Outputting a Sequence
[<- Return to INDEX 3](#index-3)

## Lambda Layers
[<- Return to INDEX 3](#index-3)

## Adjusting the Learning Rate Dynamically
[<- Return to INDEX 3](#index-3)

## More Info on Huber Loss
[<- Return to INDEX 3](#index-3)

## LSTM
[<- Return to INDEX 3](#index-3)

## Link to the LSTM Lesson
[<- Return to INDEX 3](#index-3)

## LSTM Notebook (Lab 2)
[<- Return to INDEX 3](#index-3)

## Coding LSTMs
[<- Return to INDEX 3](#index-3)

## Week 3 Quiz
[<- Return to INDEX 3](#index-3)

## Week 3 Wrap Up
[<- Return to INDEX 3](#index-3)

## Lecture Notes Week 3
[<- Return to INDEX 3](#index-3)

# Weekly Assignment Using Layers for Sequence Processing
[<- Return to INDEX 0](#index-0)

## Forecast Using RNNs or LSTMs

# Real-world Time Series Data
[<- Return to INDEX 0](#index-0)

## INDEX 4

- [A Conversation with Andrew Ng W4](#a-conversation-with-andrew-ng-w4)
- [Convolutions](#convolutions)
- [Convolutional Neural Network Course](#convolutional-neural-network-course)
- [Bi-directional LSTMs](#bi-directional-lstms)
- [More on Batch Sizing](#more-on-batch-sizing)
- [Convolutions with LSTM](#convolutions-with-lstm)
- [Real Data - Sunspots](#real-data---sunspots)
- [Train and Tune the Model](#train-and-tune-the-model)
- [Prediction](#prediction)
- [Sunspots Notebooks (Lab 2 and Lab 3)](#sunspots-notebooks-lab-2-and-lab-3)
- [Sunspots](#sunspots)
- [Combining our Tools for Analysis](#combining-our-tools-for-analysis)
- [Week 4 Quiz](#week-4-quiz)
- [Lecture Notes Week 4](#lecture-notes-week-4)
- [Reminder About the End of Access to Lab Notebooks](#reminder-about-the-end-of-access-to-lab-notebooks)
- [Wrap Up](#wrap-up)
- [Congratulations](#congratulations)
- [References](#references)
- [Acknowledgments](#acknowledgments)
- [Specialization wrap up A conversation with Andrew Ng](#specialization-wrap-up-a-conversation-with-andrew-ng)
- [What next?](#what-next)
- [Opportunity to Mentor Other Learners](#opportunity-to-mentor-other-learners)

En la última semana, nos sumergiremos en la potente combinación de Convoluciones y Redes Neuronales, incluyendo la implementación de LSTMs bidireccionales y la integración de convoluciones con LSTMs. Mediante el estudio de datos reales sobre manchas solares, aprenderemos a entrenar y ajustar modelos para realizar predicciones, utilizando todas las herramientas y técnicas analizadas hasta este punto. Cerramos con una reflexión sobre todo lo aprendido, con énfasis en cómo aplicar este conocimiento en el desarrollo de futuros proyectos, y se presenta la oportunidad de convertirse en mentor de otros aprendices, aprovechando la experiencia adquirida.

## A Conversation with Andrew Ng W4
[<- Return to INDEX 4](#index-4)

## Convolutions
[<- Return to INDEX 4](#index-4)

## Convolutional Neural Network Course
[<- Return to INDEX 4](#index-4)

## Bi-directional LSTMs
[<- Return to INDEX 4](#index-4)

## More on Batch Sizing
[<- Return to INDEX 4](#index-4)

## Convolutions with LSTM
[<- Return to INDEX 4](#index-4)

## Real Data - Sunspots
[<- Return to INDEX 4](#index-4)

## Train and Tune the Model
[<- Return to INDEX 4](#index-4)

## Prediction
[<- Return to INDEX 4](#index-4)

## Sunspots Notebooks (Lab 2 and Lab 3)
[<- Return to INDEX 4](#index-4)

## Sunspots
[<- Return to INDEX 4](#index-4)

## Combining our Tools for Analysis
[<- Return to INDEX 4](#index-4)

## Week 4 Quiz
[<- Return to INDEX 4](#index-4)

## Lecture Notes Week 4
[<- Return to INDEX 4](#index-4)

## Reminder About the End of Access to Lab Notebooks
[<- Return to INDEX 4](#index-4)

## Wrap Up
[<- Return to INDEX 4](#index-4)

## Congratulations
[<- Return to INDEX 4](#index-4)

## References
[<- Return to INDEX 4](#index-4)

## Acknowledgments
[<- Return to INDEX 4](#index-4)

## Specialization wrap up A conversation with Andrew Ng
[<- Return to INDEX 4](#index-4)

## What next?
[<- Return to INDEX 4](#index-4)

## Opportunity to Mentor Other Learners
[<- Return to INDEX 4](#index-4)

# Weekly Assignment Adding Convolutions
[<- Return to INDEX 0](#index-0)

## Adding CNNs to improve forecasts

